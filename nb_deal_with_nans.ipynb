{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.impute\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import rich\n",
    "import rich.table\n",
    "\n",
    "import lib_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib_utils.load_split_data(\"data/original.shuffled_and_split.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts_features = np.isnan(data[\"train\"][\"features\"]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3c1de25b0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([(nan_counts_features <= i).sum() for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts_ppl = np.isnan(data[\"train\"][\"features\"]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3be9d3610>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([(nan_counts_ppl <= i).sum() for i in range(nan_counts_ppl.max())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "[[ 0.         -0.02093352  0.13545709 -1.03422447]\n",
      " [ 1.22474487  1.23507745  1.15138528  1.35244738]\n",
      " [-1.22474487 -1.21414393 -1.28684238 -0.31822291]]\n",
      "(4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([82.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data = np.array([[1., 2., .0], [2, 4, .1], [3, 5, .2], [0., 1., .3],]).T\n",
    "\n",
    "print(np.nanmean(fake_data, axis=0).shape)\n",
    "fake_data -= np.nanmean(fake_data, axis=0)\n",
    "fake_data /= np.std(fake_data, axis=0)\n",
    "\n",
    "print(fake_data)\n",
    "print(fake_data.T.shape)\n",
    "np.correlate(np.arange(10) - np.arange(10).mean(), np.arange(10) - np.arange(10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib_utils.load_split_data(\"data/original.shuffled_and_split.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_mask.shape = (485512,)\n",
      "subset_indices.shape = (121099,)\n",
      "subset_data['train']['features'].shape = (6699, 121099)\n"
     ]
    }
   ],
   "source": [
    "# Nan removal\n",
    "subset_mask = (np.isnan(data[\"train\"][\"features\"]).sum(axis=0) < 10)\n",
    "subset_indices = np.arange(data[\"train\"][\"features\"].shape[1])[subset_mask]\n",
    "print(f\"{subset_mask.shape = }\")\n",
    "print(f\"{subset_indices.shape = }\")\n",
    "\n",
    "subset_data = {\n",
    "    split: {\n",
    "        information_type: information_data[:, subset_mask] \n",
    "        if information_type == \"features\" else information_data\n",
    "        for information_type, information_data in split_values.items()\n",
    "    } for split, split_values in data.items()\n",
    "}\n",
    "del data\n",
    "print(f\"{subset_data['train']['features'].shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Transforming\n",
      "imputed_subset_data['train']['features'].shape = (6699, 121099)\n"
     ]
    }
   ],
   "source": [
    "# Imputation\n",
    "imputer = sklearn.impute.SimpleImputer(strategy=\"mean\")\n",
    "print(\"Training\")\n",
    "imputer.fit(subset_data[\"train\"][\"features\"])\n",
    "\n",
    "print(\"Transforming\")\n",
    "\n",
    "imputed_subset_data = {\n",
    "    split: {\n",
    "        information_type: imputer.transform(information_data)\n",
    "        if information_type == \"features\" else information_data\n",
    "        for information_type, information_data in split_values.items()\n",
    "    } for split, split_values in subset_data.items()\n",
    "}\n",
    "del subset_data\n",
    "print(f\"{imputed_subset_data['train']['features'].shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 121099)\n",
      "(1, 121099)\n",
      "(6699, 121099)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "mean = np.nanmean(imputed_subset_data[\"train\"][\"features\"], axis=0, keepdims=True)\n",
    "print(mean.shape)\n",
    "std = np.nanstd(imputed_subset_data[\"train\"][\"features\"], axis=0, keepdims=True)\n",
    "print(std.shape)\n",
    "\n",
    "normalized_imputed_subset_data = {\n",
    "    split: {\n",
    "        information_type: (information_data - mean) / std\n",
    "        if information_type == \"features\" else information_data\n",
    "        for information_type, information_data in split_values.items()\n",
    "    } for split, split_values in imputed_subset_data.items()\n",
    "}\n",
    "del imputed_subset_data\n",
    "print(normalized_imputed_subset_data[\"train\"][\"features\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep_data(n_features, normalized_imputed_subset_data):\n",
    "    \n",
    "    feature_selector = sklearn.feature_selection.SelectKBest(\n",
    "        sklearn.feature_selection.f_regression, \n",
    "        k=n_features\n",
    "    ).fit(\n",
    "        normalized_imputed_subset_data[\"train\"][\"features\"], \n",
    "        normalized_imputed_subset_data[\"train\"][\"age\"],\n",
    "    )\n",
    "\n",
    "    feature_selected_data = {\n",
    "        split: {\n",
    "            information_type: feature_selector.transform(information_data)\n",
    "            if information_type == \"features\" else information_data\n",
    "            for information_type, information_data in split_values.items()\n",
    "        } for split, split_values in normalized_imputed_subset_data.items()\n",
    "    }\n",
    "    return feature_selected_data\n",
    "\n",
    "\n",
    "def evaluate(*, regressor, feature_selected_data, n_features, **kwargs):\n",
    "    preds = regressor.predict(feature_selected_data[\"validation\"][\"features\"])\n",
    "    mae = sklearn.metrics.mean_absolute_error(preds, feature_selected_data['validation']['age'])\n",
    "    mse = sklearn.metrics.mean_squared_error(preds, feature_selected_data['validation']['age'])\n",
    "    medae = sklearn.metrics.median_absolute_error(preds, feature_selected_data['validation']['age'])\n",
    "\n",
    "    r2 = regressor.score(\n",
    "        feature_selected_data['validation']['features'], \n",
    "        feature_selected_data['validation']['age'],\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"### Metrics ### \" + \n",
    "        f\"{r2 = :.2f} # \" +  \n",
    "        f\"{medae = :0.2f} # \" +\n",
    "        f\"{mae = :.2f} # \" +\n",
    "        f\"{mse = :.2f}\" + \n",
    "        f\"\\n### HyperParams ### {n_features = } # \" +\n",
    "        \" # \".join(f\"{k} = {v}\" for k, v in kwargs.items())\n",
    "    )\n",
    "\n",
    "def train_predict_evaluate(feature_selected_data, n_features, alpha, l1_ratio):\n",
    "    if alpha == 0:\n",
    "        regressor = sklearn.linear_model.LinearRegression(\n",
    "        )\n",
    "    elif l1_ratio == 0:\n",
    "        regressor = sklearn.linear_model.Ridge(\n",
    "            alpha=alpha,\n",
    "            max_iter=10000,\n",
    "        )\n",
    "    elif l1_ratio == 1:\n",
    "        regressor = sklearn.linear_model.Lasso(\n",
    "            alpha=alpha,\n",
    "            max_iter=10000,\n",
    "        )\n",
    "    else:\n",
    "        regressor = sklearn.linear_model.ElasticNet(\n",
    "            alpha=alpha,\n",
    "            l1_ratio=l1_ratio,\n",
    "            max_iter=10000,\n",
    "        )\n",
    "\n",
    "    regressor.fit(\n",
    "        feature_selected_data[\"train\"][\"features\"], \n",
    "        feature_selected_data[\"train\"][\"age\"],\n",
    "    )\n",
    "\n",
    "    evaluate(\n",
    "        regressor=regressor,\n",
    "        feature_selected_data=feature_selected_data,\n",
    "        n_features=n_features,\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio,\n",
    "    )\n",
    "\n",
    "    return regressor\n",
    "\n",
    "def train_histogram_gradient_boosting(feature_selected_data, n_features, learning_rate, max_iter, max_leaf_nodes):\n",
    "    regressor = sklearn.ensemble.HistGradientBoostingRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        max_iter=max_iter,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "    )\n",
    "\n",
    "    regressor.fit(\n",
    "        feature_selected_data[\"train\"][\"features\"], \n",
    "        feature_selected_data[\"train\"][\"age\"],\n",
    "    )\n",
    "\n",
    "    evaluate(\n",
    "        regressor=regressor,\n",
    "        feature_selected_data=feature_selected_data,\n",
    "        n_features=n_features,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iter=max_iter,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "    )\n",
    "\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def train_svm(feature_selected_data, n_features, kernel, degree, C):\n",
    "\n",
    "    regressor = sklearn.svm.SVR(kernel=kernel, degree=degree, C=C)\n",
    "\n",
    "    regressor.fit(\n",
    "        feature_selected_data[\"train\"][\"features\"], \n",
    "        feature_selected_data[\"train\"][\"age\"],\n",
    "    )\n",
    "\n",
    "    evaluate(\n",
    "        regressor=regressor,\n",
    "        feature_selected_data=feature_selected_data,\n",
    "        n_features=n_features,\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        C=C,\n",
    "    )\n",
    "\n",
    "    return regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Metrics ### r2 = 0.74 # medae = 6.44 # mae = 8.90 # mse = 152.89\n",
      "### HyperParams ### n_features = 10 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.44 # mae = 8.90 # mse = 152.89\n",
      "### HyperParams ### n_features = 10 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.57 # mae = 8.93 # mse = 153.17\n",
      "### HyperParams ### n_features = 10 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.51 # mae = 8.92 # mse = 153.08\n",
      "### HyperParams ### n_features = 10 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.45 # mae = 8.92 # mse = 153.09\n",
      "### HyperParams ### n_features = 10 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 9 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.43 # mae = 8.92 # mse = 153.24\n",
      "### HyperParams ### n_features = 10 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 9 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.44 # mae = 8.90 # mse = 152.89\n",
      "### HyperParams ### n_features = 10 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.64 # mae = 8.99 # mse = 154.14\n",
      "### HyperParams ### n_features = 10 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.65 # mae = 8.96 # mse = 153.79\n",
      "### HyperParams ### n_features = 10 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.51 # mae = 8.94 # mse = 153.54\n",
      "### HyperParams ### n_features = 10 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.43 # mae = 8.94 # mse = 153.65\n",
      "### HyperParams ### n_features = 10 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 9 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.44 # mae = 8.90 # mse = 152.89\n",
      "### HyperParams ### n_features = 10 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.57 # mae = 9.05 # mse = 155.26\n",
      "### HyperParams ### n_features = 10 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.60 # mae = 9.01 # mse = 154.69\n",
      "### HyperParams ### n_features = 10 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.55 # mae = 8.98 # mse = 154.20\n",
      "### HyperParams ### n_features = 10 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 10 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.74 # medae = 6.40 # mae = 8.96 # mse = 154.16\n",
      "### HyperParams ### n_features = 10 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 9 / 10\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.89 # mae = 8.30 # mse = 133.68\n",
      "### HyperParams ### n_features = 16 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.89 # mae = 8.30 # mse = 133.68\n",
      "### HyperParams ### n_features = 16 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.03 # mae = 8.39 # mse = 135.28\n",
      "### HyperParams ### n_features = 16 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.96 # mae = 8.36 # mse = 134.76\n",
      "### HyperParams ### n_features = 16 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.00 # mae = 8.34 # mse = 134.31\n",
      "### HyperParams ### n_features = 16 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.88 # mae = 8.31 # mse = 134.09\n",
      "### HyperParams ### n_features = 16 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.89 # mae = 8.30 # mse = 133.68\n",
      "### HyperParams ### n_features = 16 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.03 # mae = 8.50 # mse = 137.72\n",
      "### HyperParams ### n_features = 16 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 6% sparse\n",
      "Sparsity #: 15 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.02 # mae = 8.45 # mse = 136.76\n",
      "### HyperParams ### n_features = 16 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 14 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.92 # mae = 8.39 # mse = 135.67\n",
      "### HyperParams ### n_features = 16 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 14 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.91 # mae = 8.34 # mse = 134.72\n",
      "### HyperParams ### n_features = 16 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 14 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.89 # mae = 8.30 # mse = 133.68\n",
      "### HyperParams ### n_features = 16 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.76 # medae = 6.22 # mae = 8.59 # mse = 139.96\n",
      "### HyperParams ### n_features = 16 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 16 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.12 # mae = 8.53 # mse = 138.72\n",
      "### HyperParams ### n_features = 16 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 6% sparse\n",
      "Sparsity #: 15 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 6.00 # mae = 8.46 # mse = 137.28\n",
      "### HyperParams ### n_features = 16 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 14 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.77 # medae = 5.91 # mae = 8.37 # mse = 135.63\n",
      "### HyperParams ### n_features = 16 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 14 / 16\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.43 # mae = 7.66 # mse = 113.62\n",
      "### HyperParams ### n_features = 26 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.43 # mae = 7.66 # mse = 113.62\n",
      "### HyperParams ### n_features = 26 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.43 # mae = 7.70 # mse = 114.70\n",
      "### HyperParams ### n_features = 26 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.42 # mae = 7.69 # mse = 114.45\n",
      "### HyperParams ### n_features = 26 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.53 # mae = 7.69 # mse = 114.25\n",
      "### HyperParams ### n_features = 26 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.44 # mae = 7.68 # mse = 114.14\n",
      "### HyperParams ### n_features = 26 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.43 # mae = 7.66 # mse = 113.62\n",
      "### HyperParams ### n_features = 26 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.48 # mae = 7.76 # mse = 116.46\n",
      "### HyperParams ### n_features = 26 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 4% sparse\n",
      "Sparsity #: 25 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.41 # mae = 7.75 # mse = 115.91\n",
      "### HyperParams ### n_features = 26 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 4% sparse\n",
      "Sparsity #: 25 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.38 # mae = 7.74 # mse = 115.42\n",
      "### HyperParams ### n_features = 26 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 4% sparse\n",
      "Sparsity #: 25 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.51 # mae = 7.74 # mse = 115.17\n",
      "### HyperParams ### n_features = 26 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 8% sparse\n",
      "Sparsity #: 24 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.81 # medae = 5.43 # mae = 7.66 # mse = 113.62\n",
      "### HyperParams ### n_features = 26 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 26 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.71 # mae = 7.83 # mse = 118.20\n",
      "### HyperParams ### n_features = 26 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 4% sparse\n",
      "Sparsity #: 25 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.53 # mae = 7.81 # mse = 117.40\n",
      "### HyperParams ### n_features = 26 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 8% sparse\n",
      "Sparsity #: 24 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.48 # mae = 7.80 # mse = 116.71\n",
      "### HyperParams ### n_features = 26 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 8% sparse\n",
      "Sparsity #: 24 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.80 # medae = 5.47 # mae = 7.81 # mse = 116.36\n",
      "### HyperParams ### n_features = 26 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 23 / 26\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.30 # mae = 7.30 # mse = 99.78\n",
      "### HyperParams ### n_features = 42 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 42 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.30 # mae = 7.30 # mse = 99.78\n",
      "### HyperParams ### n_features = 42 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 42 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.19 # mae = 7.30 # mse = 99.48\n",
      "### HyperParams ### n_features = 42 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 42 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.22 # mae = 7.30 # mse = 99.44\n",
      "### HyperParams ### n_features = 42 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 2% sparse\n",
      "Sparsity #: 41 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.24 # mae = 7.29 # mse = 99.41\n",
      "### HyperParams ### n_features = 42 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 7% sparse\n",
      "Sparsity #: 39 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.21 # mae = 7.29 # mse = 99.37\n",
      "### HyperParams ### n_features = 42 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 38 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.30 # mae = 7.30 # mse = 99.78\n",
      "### HyperParams ### n_features = 42 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 42 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.30 # mae = 7.36 # mse = 100.70\n",
      "### HyperParams ### n_features = 42 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 2% sparse\n",
      "Sparsity #: 41 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.29 # mae = 7.35 # mse = 100.36\n",
      "### HyperParams ### n_features = 42 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 5% sparse\n",
      "Sparsity #: 40 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.35 # mae = 7.35 # mse = 100.20\n",
      "### HyperParams ### n_features = 42 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 38 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.31 # mae = 7.34 # mse = 100.04\n",
      "### HyperParams ### n_features = 42 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 17% sparse\n",
      "Sparsity #: 35 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.30 # mae = 7.30 # mse = 99.78\n",
      "### HyperParams ### n_features = 42 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 42 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.32 # mae = 7.43 # mse = 102.41\n",
      "### HyperParams ### n_features = 42 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 2% sparse\n",
      "Sparsity #: 41 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.35 # mae = 7.41 # mse = 101.86\n",
      "### HyperParams ### n_features = 42 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 7% sparse\n",
      "Sparsity #: 39 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.36 # mae = 7.41 # mse = 101.56\n",
      "### HyperParams ### n_features = 42 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 37 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.83 # medae = 5.34 # mae = 7.41 # mse = 101.37\n",
      "### HyperParams ### n_features = 42 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 24% sparse\n",
      "Sparsity #: 32 / 42\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.68 # mae = 6.39 # mse = 77.45\n",
      "### HyperParams ### n_features = 69 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 69 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.68 # mae = 6.39 # mse = 77.45\n",
      "### HyperParams ### n_features = 69 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 69 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.71 # mae = 6.43 # mse = 78.68\n",
      "### HyperParams ### n_features = 69 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 3% sparse\n",
      "Sparsity #: 67 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.68 # mae = 6.43 # mse = 78.58\n",
      "### HyperParams ### n_features = 69 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 9% sparse\n",
      "Sparsity #: 63 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.63 # mae = 6.44 # mse = 78.46\n",
      "### HyperParams ### n_features = 69 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 62 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.63 # mae = 6.45 # mse = 78.28\n",
      "### HyperParams ### n_features = 69 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 17% sparse\n",
      "Sparsity #: 57 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.68 # mae = 6.39 # mse = 77.45\n",
      "### HyperParams ### n_features = 69 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 69 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.70 # mae = 6.51 # mse = 80.67\n",
      "### HyperParams ### n_features = 69 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 7% sparse\n",
      "Sparsity #: 64 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.72 # mae = 6.51 # mse = 80.42\n",
      "### HyperParams ### n_features = 69 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 17% sparse\n",
      "Sparsity #: 57 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.67 # mae = 6.52 # mse = 80.05\n",
      "### HyperParams ### n_features = 69 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 25% sparse\n",
      "Sparsity #: 52 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.66 # mae = 6.53 # mse = 79.81\n",
      "### HyperParams ### n_features = 69 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 28% sparse\n",
      "Sparsity #: 50 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.87 # medae = 4.68 # mae = 6.39 # mse = 77.45\n",
      "### HyperParams ### n_features = 69 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 69 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.73 # mae = 6.59 # mse = 82.56\n",
      "### HyperParams ### n_features = 69 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 62 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.65 # mae = 6.59 # mse = 82.22\n",
      "### HyperParams ### n_features = 69 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 22% sparse\n",
      "Sparsity #: 54 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.69 # mae = 6.60 # mse = 81.93\n",
      "### HyperParams ### n_features = 69 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 28% sparse\n",
      "Sparsity #: 50 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.86 # medae = 4.69 # mae = 6.63 # mse = 81.93\n",
      "### HyperParams ### n_features = 69 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 38% sparse\n",
      "Sparsity #: 43 / 69\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.35 # mae = 5.92 # mse = 67.85\n",
      "### HyperParams ### n_features = 112 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 112 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.35 # mae = 5.92 # mse = 67.85\n",
      "### HyperParams ### n_features = 112 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 112 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.37 # mae = 5.98 # mse = 68.80\n",
      "### HyperParams ### n_features = 112 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 2% sparse\n",
      "Sparsity #: 110 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.36 # mae = 5.98 # mse = 68.80\n",
      "### HyperParams ### n_features = 112 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 8% sparse\n",
      "Sparsity #: 103 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.30 # mae = 5.98 # mse = 68.70\n",
      "### HyperParams ### n_features = 112 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 18% sparse\n",
      "Sparsity #: 92 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.35 # mae = 5.98 # mse = 68.40\n",
      "### HyperParams ### n_features = 112 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 27% sparse\n",
      "Sparsity #: 82 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.35 # mae = 5.92 # mse = 67.85\n",
      "### HyperParams ### n_features = 112 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 112 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.41 # mae = 6.05 # mse = 70.74\n",
      "### HyperParams ### n_features = 112 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 6% sparse\n",
      "Sparsity #: 105 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.45 # mae = 6.06 # mse = 70.70\n",
      "### HyperParams ### n_features = 112 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 15% sparse\n",
      "Sparsity #: 95 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.40 # mae = 6.07 # mse = 70.73\n",
      "### HyperParams ### n_features = 112 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 26% sparse\n",
      "Sparsity #: 83 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.44 # mae = 6.07 # mse = 70.22\n",
      "### HyperParams ### n_features = 112 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 36% sparse\n",
      "Sparsity #: 72 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.35 # mae = 5.92 # mse = 67.85\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 112 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.33 # mae = 6.13 # mse = 72.86\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 6% sparse\n",
      "Sparsity #: 105 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.38 # mae = 6.14 # mse = 72.98\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 21% sparse\n",
      "Sparsity #: 88 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.51 # mae = 6.15 # mse = 72.93\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 35% sparse\n",
      "Sparsity #: 73 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.88 # medae = 4.57 # mae = 6.15 # mse = 72.56\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 48% sparse\n",
      "Sparsity #: 58 / 112\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.89 # mae = 5.51 # mse = 60.72\n",
      "### HyperParams ### n_features = 183 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 183 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.89 # mae = 5.51 # mse = 60.72\n",
      "### HyperParams ### n_features = 183 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 183 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.89 # mae = 5.46 # mse = 59.59\n",
      "### HyperParams ### n_features = 183 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 8% sparse\n",
      "Sparsity #: 169 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.97 # mae = 5.47 # mse = 59.66\n",
      "### HyperParams ### n_features = 183 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 17% sparse\n",
      "Sparsity #: 152 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.92 # mae = 5.48 # mse = 59.67\n",
      "### HyperParams ### n_features = 183 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 22% sparse\n",
      "Sparsity #: 142 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.98 # mae = 5.51 # mse = 59.85\n",
      "### HyperParams ### n_features = 183 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 28% sparse\n",
      "Sparsity #: 132 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.89 # mae = 5.51 # mse = 60.72\n",
      "### HyperParams ### n_features = 183 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 183 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.92 # mae = 5.51 # mse = 60.51\n",
      "### HyperParams ### n_features = 183 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 10% sparse\n",
      "Sparsity #: 165 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.91 # mae = 5.54 # mse = 60.90\n",
      "### HyperParams ### n_features = 183 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 21% sparse\n",
      "Sparsity #: 144 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 4.07 # mae = 5.57 # mse = 61.30\n",
      "### HyperParams ### n_features = 183 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 34% sparse\n",
      "Sparsity #: 121 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 4.15 # mae = 5.63 # mse = 62.09\n",
      "### HyperParams ### n_features = 183 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 46% sparse\n",
      "Sparsity #: 99 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.89 # mae = 5.51 # mse = 60.71\n",
      "### HyperParams ### n_features = 183 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 183 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.94 # mae = 5.59 # mse = 62.11\n",
      "### HyperParams ### n_features = 183 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 15% sparse\n",
      "Sparsity #: 155 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 3.99 # mae = 5.62 # mse = 62.69\n",
      "### HyperParams ### n_features = 183 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 31% sparse\n",
      "Sparsity #: 126 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.15 # mae = 5.68 # mse = 63.46\n",
      "### HyperParams ### n_features = 183 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 45% sparse\n",
      "Sparsity #: 101 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.89 # medae = 4.10 # mae = 5.74 # mse = 64.39\n",
      "### HyperParams ### n_features = 183 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 56% sparse\n",
      "Sparsity #: 81 / 183\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.63 # mae = 5.15 # mse = 55.94\n",
      "### HyperParams ### n_features = 297 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 297 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.63 # mae = 5.15 # mse = 55.94\n",
      "### HyperParams ### n_features = 297 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 297 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.72 # mae = 5.09 # mse = 54.19\n",
      "### HyperParams ### n_features = 297 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 12% sparse\n",
      "Sparsity #: 260 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.69 # mae = 5.09 # mse = 54.49\n",
      "### HyperParams ### n_features = 297 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 24% sparse\n",
      "Sparsity #: 226 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.63 # mae = 5.11 # mse = 55.01\n",
      "### HyperParams ### n_features = 297 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 33% sparse\n",
      "Sparsity #: 198 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.69 # mae = 5.14 # mse = 55.32\n",
      "### HyperParams ### n_features = 297 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 46% sparse\n",
      "Sparsity #: 161 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.63 # mae = 5.15 # mse = 55.94\n",
      "### HyperParams ### n_features = 297 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 297 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.69 # mae = 5.15 # mse = 55.00\n",
      "### HyperParams ### n_features = 297 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 21% sparse\n",
      "Sparsity #: 235 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.74 # mae = 5.18 # mse = 55.65\n",
      "### HyperParams ### n_features = 297 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 37% sparse\n",
      "Sparsity #: 187 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.72 # mae = 5.21 # mse = 56.22\n",
      "### HyperParams ### n_features = 297 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 49% sparse\n",
      "Sparsity #: 152 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.65 # mae = 5.25 # mse = 56.38\n",
      "### HyperParams ### n_features = 297 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 60% sparse\n",
      "Sparsity #: 119 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.63 # mae = 5.15 # mse = 55.94\n",
      "### HyperParams ### n_features = 297 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 297 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.79 # mae = 5.23 # mse = 56.19\n",
      "### HyperParams ### n_features = 297 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 24% sparse\n",
      "Sparsity #: 225 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.82 # mae = 5.28 # mse = 57.02\n",
      "### HyperParams ### n_features = 297 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 42% sparse\n",
      "Sparsity #: 172 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.76 # mae = 5.33 # mse = 57.62\n",
      "### HyperParams ### n_features = 297 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 56% sparse\n",
      "Sparsity #: 130 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.90 # medae = 3.85 # mae = 5.37 # mse = 58.08\n",
      "### HyperParams ### n_features = 297 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 69% sparse\n",
      "Sparsity #: 91 / 297\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.45 # mae = 4.74 # mse = 47.60\n",
      "### HyperParams ### n_features = 483 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 483 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.45 # mae = 4.74 # mse = 47.60\n",
      "### HyperParams ### n_features = 483 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 483 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.41 # mae = 4.68 # mse = 47.82\n",
      "### HyperParams ### n_features = 483 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 16% sparse\n",
      "Sparsity #: 406 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.40 # mae = 4.69 # mse = 48.01\n",
      "### HyperParams ### n_features = 483 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 31% sparse\n",
      "Sparsity #: 333 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.37 # mae = 4.72 # mse = 48.18\n",
      "### HyperParams ### n_features = 483 # alpha = 0.06666666666666667 # l1_ratio = 0.75\n",
      "Sparsity %: 41% sparse\n",
      "Sparsity #: 286 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.41 # mae = 4.76 # mse = 48.54\n",
      "### HyperParams ### n_features = 483 # alpha = 0.06666666666666667 # l1_ratio = 1.0\n",
      "Sparsity %: 52% sparse\n",
      "Sparsity #: 230 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.45 # mae = 4.74 # mse = 47.60\n",
      "### HyperParams ### n_features = 483 # alpha = 0.13333333333333333 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 483 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.46 # mae = 4.75 # mse = 49.11\n",
      "### HyperParams ### n_features = 483 # alpha = 0.13333333333333333 # l1_ratio = 0.25\n",
      "Sparsity %: 28% sparse\n",
      "Sparsity #: 347 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.49 # mae = 4.80 # mse = 49.88\n",
      "### HyperParams ### n_features = 483 # alpha = 0.13333333333333333 # l1_ratio = 0.5\n",
      "Sparsity %: 45% sparse\n",
      "Sparsity #: 265 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.45 # mae = 4.86 # mse = 50.47\n",
      "### HyperParams ### n_features = 483 # alpha = 0.13333333333333333 # l1_ratio = 0.75\n",
      "Sparsity %: 59% sparse\n",
      "Sparsity #: 198 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.50 # mae = 4.91 # mse = 50.66\n",
      "### HyperParams ### n_features = 483 # alpha = 0.13333333333333333 # l1_ratio = 1.0\n",
      "Sparsity %: 71% sparse\n",
      "Sparsity #: 141 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.45 # mae = 4.74 # mse = 47.60\n",
      "### HyperParams ### n_features = 483 # alpha = 0.2 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 483 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.45 # mae = 4.83 # mse = 50.51\n",
      "### HyperParams ### n_features = 483 # alpha = 0.2 # l1_ratio = 0.25\n",
      "Sparsity %: 34% sparse\n",
      "Sparsity #: 321 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.54 # mae = 4.91 # mse = 51.52\n",
      "### HyperParams ### n_features = 483 # alpha = 0.2 # l1_ratio = 0.5\n",
      "Sparsity %: 54% sparse\n",
      "Sparsity #: 223 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.65 # mae = 4.98 # mse = 52.01\n",
      "### HyperParams ### n_features = 483 # alpha = 0.2 # l1_ratio = 0.75\n",
      "Sparsity %: 67% sparse\n",
      "Sparsity #: 157 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.71 # mae = 5.07 # mse = 52.42\n",
      "### HyperParams ### n_features = 483 # alpha = 0.2 # l1_ratio = 1.0\n",
      "Sparsity %: 79% sparse\n",
      "Sparsity #: 101 / 483\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.13 # mae = 4.67 # mse = 51.90\n",
      "### HyperParams ### n_features = 784 # alpha = 0.0 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 784 / 784\n",
      "\n",
      "### Metrics ### r2 = 0.91 # medae = 3.12 # mae = 4.67 # mse = 51.89\n",
      "### HyperParams ### n_features = 784 # alpha = 0.06666666666666667 # l1_ratio = 0.0\n",
      "Sparsity %: 0% sparse\n",
      "Sparsity #: 784 / 784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/.main/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+03, tolerance: 3.931e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Metrics ### r2 = 0.92 # medae = 3.14 # mae = 4.49 # mse = 47.82\n",
      "### HyperParams ### n_features = 784 # alpha = 0.06666666666666667 # l1_ratio = 0.25\n",
      "Sparsity %: 22% sparse\n",
      "Sparsity #: 613 / 784\n",
      "\n",
      "### Metrics ### r2 = 0.92 # medae = 3.26 # mae = 4.52 # mse = 47.52\n",
      "### HyperParams ### n_features = 784 # alpha = 0.06666666666666667 # l1_ratio = 0.5\n",
      "Sparsity %: 39% sparse\n",
      "Sparsity #: 478 / 784\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m alpha \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m4\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m l1_ratio \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, (\u001b[39m5\u001b[39m \u001b[39mif\u001b[39;00m alpha \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)):\n\u001b[0;32m---> 17\u001b[0m         estimator \u001b[39m=\u001b[39m train_predict_evaluate(\n\u001b[1;32m     18\u001b[0m             feature_selected_data\u001b[39m=\u001b[39;49mfeature_selected_data, \n\u001b[1;32m     19\u001b[0m             alpha\u001b[39m=\u001b[39;49malpha, \n\u001b[1;32m     20\u001b[0m             l1_ratio\u001b[39m=\u001b[39;49ml1_ratio, \n\u001b[1;32m     21\u001b[0m             n_features\u001b[39m=\u001b[39;49mn_features\n\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mcoef_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     24\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSparsity %: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39misclose(estimator\u001b[39m.\u001b[39mcoef_,\u001b[39m \u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m0.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sparse\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 63\u001b[0m, in \u001b[0;36mtrain_predict_evaluate\u001b[0;34m(feature_selected_data, n_features, alpha, l1_ratio)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     regressor \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mlinear_model\u001b[39m.\u001b[39mElasticNet(\n\u001b[1;32m     58\u001b[0m         alpha\u001b[39m=\u001b[39malpha,\n\u001b[1;32m     59\u001b[0m         l1_ratio\u001b[39m=\u001b[39ml1_ratio,\n\u001b[1;32m     60\u001b[0m         max_iter\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m,\n\u001b[1;32m     61\u001b[0m     )\n\u001b[0;32m---> 63\u001b[0m regressor\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     64\u001b[0m     feature_selected_data[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[1;32m     65\u001b[0m     feature_selected_data[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mage\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m evaluate(\n\u001b[1;32m     69\u001b[0m     regressor\u001b[39m=\u001b[39mregressor,\n\u001b[1;32m     70\u001b[0m     feature_selected_data\u001b[39m=\u001b[39mfeature_selected_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     l1_ratio\u001b[39m=\u001b[39ml1_ratio,\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m regressor\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1004\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m     this_Xy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath(\n\u001b[1;32m   1005\u001b[0m     X,\n\u001b[1;32m   1006\u001b[0m     y[:, k],\n\u001b[1;32m   1007\u001b[0m     l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1008\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1009\u001b[0m     n_alphas\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1010\u001b[0m     alphas\u001b[39m=\u001b[39;49m[alpha],\n\u001b[1;32m   1011\u001b[0m     precompute\u001b[39m=\u001b[39;49mprecompute,\n\u001b[1;32m   1012\u001b[0m     Xy\u001b[39m=\u001b[39;49mthis_Xy,\n\u001b[1;32m   1013\u001b[0m     copy_X\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1014\u001b[0m     coef_init\u001b[39m=\u001b[39;49mcoef_[k],\n\u001b[1;32m   1015\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1016\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1017\u001b[0m     positive\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositive,\n\u001b[1;32m   1018\u001b[0m     check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1019\u001b[0m     \u001b[39m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1020\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1021\u001b[0m     X_offset\u001b[39m=\u001b[39;49mX_offset,\n\u001b[1;32m   1022\u001b[0m     X_scale\u001b[39m=\u001b[39;49mX_scale,\n\u001b[1;32m   1023\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1024\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1025\u001b[0m     selection\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselection,\n\u001b[1;32m   1026\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1027\u001b[0m )\n\u001b[1;32m   1028\u001b[0m coef_[k] \u001b[39m=\u001b[39m this_coef[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m   1029\u001b[0m dual_gaps_[k] \u001b[39m=\u001b[39m this_dual_gap[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    617\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    618\u001b[0m         coef_,\n\u001b[1;32m    619\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         positive,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[39melif\u001b[39;00m precompute \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39;49menet_coordinate_descent(\n\u001b[1;32m    632\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    636\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPrecompute should be one of True, False, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or array-like. Got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[39m%\u001b[39m precompute\n\u001b[1;32m    638\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "table = rich.table.Table(\n",
    "    \"[bold]N_features]\", \n",
    "    \"[bold]Alpha\", \n",
    "    \"[bold]L1 Ratio\", \n",
    "    \"[bold]R2\",\n",
    "    \"[bold]MEDIAN AE\",\n",
    "    \"[bold]MAE\", \n",
    "    \"[bold]MSE\", \n",
    "    show_lines=True,\n",
    ")\n",
    "\n",
    "for n_features_exp in np.linspace(1, 5, 20):\n",
    "    n_features = int(10 ** n_features_exp)\n",
    "    feature_selected_data = prep_data(n_features, normalized_imputed_subset_data)\n",
    "    for alpha in np.linspace(0, 0.2, 4):\n",
    "        for l1_ratio in np.linspace(0, 1, (5 if alpha != 0 else 1)):\n",
    "            estimator = train_predict_evaluate(\n",
    "                feature_selected_data=feature_selected_data, \n",
    "                alpha=alpha, \n",
    "                l1_ratio=l1_ratio, \n",
    "                n_features=n_features\n",
    "            )\n",
    "            if hasattr(estimator, \"coef_\"):\n",
    "                print(f\"Sparsity %: {np.isclose(estimator.coef_, 0).mean():0.0%} sparse\")\n",
    "                print(f\"Sparsity #: {len(estimator.coef_) - np.isclose(estimator.coef_, 0).sum()} / {len(estimator.coef_)}\")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Metrics ### r2 = 0.88 # medae = 4.57 # mae = 6.15 # mse = 72.56\n",
      "### HyperParams ### n_features = 112 # alpha = 0.2 # l1_ratio = 1.0\n"
     ]
    }
   ],
   "source": [
    "### Metrics ### r2 = 0.90 # medae = 3.85 # mae = 5.37 # mse = 58.08\n",
    "### HyperParams ### {n_features = } # alpha = 0.2 # l1_ratio = 1.0\n",
    "\n",
    "# n_features = 112 # alpha = 0.2 # l1_ratio = 1.0\n",
    "alpha = 0.2\n",
    "l1_ratio = 1.0\n",
    "n_features = 112\n",
    "feature_selected_data = prep_data(n_features, normalized_imputed_subset_data)\n",
    "estimator = train_predict_evaluate(\n",
    "    feature_selected_data=feature_selected_data, \n",
    "    alpha=alpha, \n",
    "    l1_ratio=l1_ratio, \n",
    "    n_features=n_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 2 r2 = 0.63 medae = 8.85 mae = 11.39 mse = 219.67\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 8 r2 = 0.63 medae = 8.95 mae = 11.31 mse = 219.00\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 40 r2 = 0.62 medae = 9.07 mae = 11.40 mse = 222.69\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 166 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 579 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 1759 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 4784 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 11882 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 27352 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 1 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 59050 r2 = 0.62 medae = 9.11 mae = 11.42 mse = 223.75\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 2 r2 = 0.77 medae = 6.63 mae = 8.67 mse = 135.88\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 8 r2 = 0.85 medae = 4.82 mae = 6.69 mse = 87.33\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 40 r2 = 0.88 medae = 4.19 mae = 5.93 mse = 72.77\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 166 r2 = 0.88 medae = 4.07 mae = 5.79 mse = 69.74\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 579 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 1759 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 4784 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 11882 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 27352 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 10 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 59050 r2 = 0.88 medae = 4.07 mae = 5.76 mse = 70.25\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 2 r2 = 0.82 medae = 6.06 mae = 7.68 mse = 103.83\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 8 r2 = 0.90 medae = 4.23 mae = 5.45 mse = 57.31\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 40 r2 = 0.92 medae = 3.36 mae = 4.68 mse = 45.21\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 166 r2 = 0.93 medae = 3.03 mae = 4.50 mse = 44.34\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 579 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 1759 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 4784 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 11882 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 27352 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 68 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 59050 r2 = 0.92 medae = 3.17 mae = 4.60 mse = 45.28\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 2 r2 = 0.85 medae = 5.49 mae = 7.21 mse = 90.65\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 8 r2 = 0.92 medae = 3.68 mae = 4.91 mse = 48.37\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 40 r2 = 0.93 medae = 3.01 mae = 4.23 mse = 39.02\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 166 r2 = 0.94 medae = 2.69 mae = 4.08 mse = 38.39\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 579 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 1759 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 4784 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 11882 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 27352 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 336 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 59050 r2 = 0.94 medae = 2.77 mae = 4.11 mse = 38.32\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 2 r2 = 0.86 medae = 5.42 mae = 6.95 mse = 84.86\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 8 r2 = 0.92 medae = 3.44 mae = 4.78 mse = 46.76\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 40 r2 = 0.94 medae = 2.80 mae = 4.04 mse = 35.10\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 166 r2 = 0.94 medae = 2.74 mae = 4.01 mse = 36.83\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 579 r2 = 0.93 medae = 2.89 mae = 4.13 mse = 38.86\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 1759 r2 = 0.93 medae = 2.89 mae = 4.13 mse = 38.86\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 4784 r2 = 0.93 medae = 2.89 mae = 4.13 mse = 38.86\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 11882 r2 = 0.93 medae = 2.89 mae = 4.13 mse = 38.86\n",
      "n_features = 1327 learning_rate = 0.1 max_iter = 100 max_leaf_nodes = 27352 r2 = 0.93 medae = 2.89 mae = 4.13 mse = 38.86\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m      9\u001b[0m         max_leaf_nodes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(j \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)    \n\u001b[0;32m---> 10\u001b[0m         estimator \u001b[39m=\u001b[39m train_histogram_gradient_boosting(\n\u001b[1;32m     11\u001b[0m             feature_selected_data, n_features, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, max_leaf_nodes\u001b[39m=\u001b[39;49mmax_leaf_nodes\n\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mcoef_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSparsity %: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39misclose(estimator\u001b[39m.\u001b[39mcoef_,\u001b[39m \u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m0.0%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sparse\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 84\u001b[0m, in \u001b[0;36mtrain_histogram_gradient_boosting\u001b[0;34m(feature_selected_data, n_features, learning_rate, max_iter, max_leaf_nodes)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_histogram_gradient_boosting\u001b[39m(feature_selected_data, n_features, learning_rate, max_iter, max_leaf_nodes):\n\u001b[1;32m     78\u001b[0m     regressor \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mensemble\u001b[39m.\u001b[39mHistGradientBoostingRegressor(\n\u001b[1;32m     79\u001b[0m         learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m     80\u001b[0m         max_iter\u001b[39m=\u001b[39mmax_iter,\n\u001b[1;32m     81\u001b[0m         max_leaf_nodes\u001b[39m=\u001b[39mmax_leaf_nodes,\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     regressor\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     85\u001b[0m         feature_selected_data[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[1;32m     86\u001b[0m         feature_selected_data[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mage\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     evaluate(\n\u001b[1;32m     90\u001b[0m         regressor\u001b[39m=\u001b[39mregressor,\n\u001b[1;32m     91\u001b[0m         feature_selected_data\u001b[39m=\u001b[39mfeature_selected_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m         max_leaf_nodes\u001b[39m=\u001b[39mmax_leaf_nodes,\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m regressor\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:670\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[39m# Build `n_trees_per_iteration` trees.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_trees_per_iteration_):\n\u001b[0;32m--> 670\u001b[0m     grower \u001b[39m=\u001b[39m TreeGrower(\n\u001b[1;32m    671\u001b[0m         X_binned\u001b[39m=\u001b[39;49mX_binned_train,\n\u001b[1;32m    672\u001b[0m         gradients\u001b[39m=\u001b[39;49mg_view[:, k],\n\u001b[1;32m    673\u001b[0m         hessians\u001b[39m=\u001b[39;49mh_view[:, k],\n\u001b[1;32m    674\u001b[0m         n_bins\u001b[39m=\u001b[39;49mn_bins,\n\u001b[1;32m    675\u001b[0m         n_bins_non_missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bin_mapper\u001b[39m.\u001b[39;49mn_bins_non_missing_,\n\u001b[1;32m    676\u001b[0m         has_missing_values\u001b[39m=\u001b[39;49mhas_missing_values,\n\u001b[1;32m    677\u001b[0m         is_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_categorical_,\n\u001b[1;32m    678\u001b[0m         monotonic_cst\u001b[39m=\u001b[39;49mmonotonic_cst,\n\u001b[1;32m    679\u001b[0m         interaction_cst\u001b[39m=\u001b[39;49minteraction_cst,\n\u001b[1;32m    680\u001b[0m         max_leaf_nodes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_leaf_nodes,\n\u001b[1;32m    681\u001b[0m         max_depth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_depth,\n\u001b[1;32m    682\u001b[0m         min_samples_leaf\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_samples_leaf,\n\u001b[1;32m    683\u001b[0m         l2_regularization\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml2_regularization,\n\u001b[1;32m    684\u001b[0m         shrinkage\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m    685\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m     grower\u001b[39m.\u001b[39mgrow()\n\u001b[1;32m    689\u001b[0m     acc_apply_split_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m grower\u001b[39m.\u001b[39mtotal_apply_split_time\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:332\u001b[0m, in \u001b[0;36mTreeGrower.__init__\u001b[0;34m(self, X_binned, gradients, hessians, max_leaf_nodes, max_depth, min_samples_leaf, min_gain_to_split, n_bins, n_bins_non_missing, has_missing_values, is_categorical, monotonic_cst, interaction_cst, l2_regularization, min_hessian_to_split, shrinkage, n_threads)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_apply_split_time \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# time spent splitting nodes\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_categorical_splits \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 332\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intilialize_root(gradients, hessians, hessians_are_constant)\n\u001b[1;32m    333\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_nodes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:416\u001b[0m, in \u001b[0;36mTreeGrower._intilialize_root\u001b[0;34m(self, gradients, hessians, hessians_are_constant)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mallowed_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfromiter(\n\u001b[1;32m    412\u001b[0m         allowed_features, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint32, count\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(allowed_features)\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    415\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 416\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mhistograms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhistogram_builder\u001b[39m.\u001b[39;49mcompute_histograms_brute(\n\u001b[1;32m    417\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot\u001b[39m.\u001b[39;49msample_indices, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot\u001b[39m.\u001b[39;49mallowed_features\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_compute_hist_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m tic\n\u001b[1;32m    421\u001b[0m tic \u001b[39m=\u001b[39m time()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 0.1\n",
    "l1_ratio = 0.6\n",
    "\n",
    "for i in np.linspace(1, 6, 20):\n",
    "    n_features = int(i ** 10)\n",
    "    feature_selected_data = prep_data(n_features, normalized_imputed_subset_data)\n",
    "\n",
    "    for j in np.linspace(1, 3, 10):\n",
    "        max_leaf_nodes = 1 + int(j ** 10)    \n",
    "        estimator = train_histogram_gradient_boosting(\n",
    "            feature_selected_data, n_features, learning_rate=0.1, max_iter=100, max_leaf_nodes=max_leaf_nodes\n",
    "        )\n",
    "\n",
    "\n",
    "if hasattr(estimator, \"coef_\"):\n",
    "    print(f\"Sparsity %: {np.isclose(estimator.coef_, 0).mean():0.0%} sparse\")\n",
    "    print(f\"Sparsity #: {len(estimator.coef_) - np.isclose(estimator.coef_, 0).sum()} / {len(estimator.coef_)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity %: 67% sparse\n",
      "Sparsity #: 659 / 2000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sparsity %: {np.isclose(estimator.coef_, 0).mean():0.0%} sparse\")\n",
    "print(f\"Sparsity #: {len(estimator.coef_) - np.isclose(estimator.coef_, 0).sum()} / {len(estimator.coef_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1 - np.isclose(estimator.coef_, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401.2800000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(estimator.coef_) * (1 - .71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
